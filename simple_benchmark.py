#!/usr/bin/env python3
"""Simple performance benchmark for Oracle Target."""

import time
from datetime import datetime, timezone

from flext_target_oracle.connectors import OracleConnector


def benchmark_type_conversions():
    """Benchmark type conversion performance."""
    print("üöÄ Oracle Target Type Conversion Benchmark\n")

    connector = OracleConnector({})

    # Test cases
    test_cases = [
        ("integer", {"type": "integer"}),
        ("number", {"type": "number"}),
        ("boolean", {"type": "boolean"}),
        ("string", {"type": "string", "maxLength": 255}),
        ("datetime", {"type": "string", "format": "date-time"}),
        ("clob", {"type": "string", "maxLength": 5000}),
        ("object", {"type": "object"})
    ]

    iterations = 100000

    print(f"üìä Testing {iterations:,} conversions per type:\n")

    total_start = time.time()

    for name, schema in test_cases:
        start_time = time.time()

        for _ in range(iterations):
            connector.to_sql_type(schema)

        elapsed = time.time() - start_time
        conversions_per_second = iterations / elapsed if elapsed > 0 else 0

        print(
            f"  {name:<15}: {conversions_per_second:>12,.0f} "
            f"conversions/second ({elapsed:.3f}s)"
        )

    total_elapsed = time.time() - total_start
    print(f"\n  Total time: {total_elapsed:.2f}s")
    print(
        f"  Average: {(iterations * len(test_cases)) / total_elapsed:,.0f} "
        f"conversions/second"
    )


def benchmark_pool_selection():
    """Benchmark connection pool selection."""
    print("\nüìä Connection Pool Selection Performance:\n")

    configs = [
        ("No pooling", {"pool_size": 0}),
        ("Single connection", {"pool_size": 1}),
        ("Small pool", {"pool_size": 5}),
        ("Default pool", {"pool_size": 10}),
        ("Large pool", {"pool_size": 50})
    ]

    iterations = 100000

    for name, config in configs:
        connector = OracleConnector(config)

        start_time = time.time()
        for _ in range(iterations):
            pool_class = connector._get_pool_class()

        elapsed = time.time() - start_time
        selections_per_second = iterations / elapsed if elapsed > 0 else 0

        print(
            f"  {name:<20}: {pool_class.__name__:<15} "
            f"({selections_per_second:>10,.0f} selections/second)"
        )


def benchmark_column_patterns():
    """Benchmark column pattern recognition."""
    print("\nüìä Column Pattern Recognition Performance:\n")

    connector = OracleConnector({"enable_column_patterns": True})

    # Test different column patterns
    test_columns = [
        ("USER_ID", {"type": "integer"}),
        ("ORDER_AMOUNT", {"type": "number"}),
        ("ACTIVE_FLG", {"type": "boolean"}),
        ("CREATE_TS", {"type": "string"}),
        ("DESCRIPTION", {"type": "string"}),
        ("PRODUCT_CODE", {"type": "string"}),
        ("CUSTOMER_NAME", {"type": "string"})
    ]

    iterations = 50000

    for col_name, schema in test_columns:
        start_time = time.time()

        for _ in range(iterations):
            connector.get_column_type(col_name, schema)

        elapsed = time.time() - start_time
        ops_per_second = iterations / elapsed if elapsed > 0 else 0

        print(f"  {col_name:<20}: {ops_per_second:>12,.0f} operations/second")


def benchmark_url_creation():
    """Benchmark URL creation performance."""
    print("\nüìä SQLAlchemy URL Creation Performance:\n")

    configs = [
        {
            "host": "localhost",
            "username": "user1",
            "password": "pass1",
            "service_name": "ORCL"
        },
        {
            "host": "remote.oracle.com",
            "username": "app_user",
            "password": "secure_password_123",
            "service_name": "PROD_DB",
            "port": 1522
        }
    ]

    iterations = 50000

    for i, config in enumerate(configs, 1):
        connector = OracleConnector({})

        start_time = time.time()
        for _ in range(iterations):
            url = connector.get_sqlalchemy_url(config)

        elapsed = time.time() - start_time
        urls_per_second = iterations / elapsed if elapsed > 0 else 0

        print(f"  Config {i}: {urls_per_second:>12,.0f} URLs/second")
        print(f"    Sample URL: {url}")


def benchmark_audit_fields():
    """Benchmark audit field generation."""
    print("\nüìä Audit Field Generation Performance:\n")

    iterations = 100000

    # Simulate record preparation with audit fields
    start_time = time.time()

    for _ in range(iterations):
        now = datetime.now(timezone.utc)
        _ = {
            "CREATE_TS": now,
            "MOD_TS": now,
            "CREATE_USER": "SINGER",
            "MOD_USER": "SINGER"
        }

    elapsed = time.time() - start_time
    ops_per_second = iterations / elapsed if elapsed > 0 else 0

    print(f"  Audit field generation: {ops_per_second:>12,.0f} operations/second")


def main():
    """Run all benchmarks."""
    print("=" * 60)
    print("Oracle Target Performance Benchmarks")
    print("Testing SQLAlchemy 2.0 Implementation")
    print("=" * 60)

    try:
        benchmark_type_conversions()
        benchmark_pool_selection()
        benchmark_column_patterns()
        benchmark_url_creation()
        benchmark_audit_fields()

        print("\n‚úÖ All benchmarks completed successfully!")
        print("\nüìà Performance Summary:")
        print("  - Type conversions are highly optimized")
        print("  - Pool selection is instantaneous")
        print("  - Column pattern recognition is efficient")
        print("  - URL creation uses SQLAlchemy 2.0 URL.create()")
        print("  - Audit field overhead is minimal")

    except Exception as e:
        print(f"\n‚ùå Benchmark failed: {e}")
        import traceback
        traceback.print_exc()
        exit(1)


if __name__ == "__main__":
    main()
